{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from time import perf_counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Site:\n",
    "    \"\"\"\n",
    "    Define a estutura base do site do g1.globo.\n",
    "    Tanto da página principal quanto das páginas\n",
    "    de artigos\n",
    "    \"\"\"\n",
    "    def __init__(self, main, a, h1, h2, p):\n",
    "        self._main = main\n",
    "        self._a = a\n",
    "        self._h1 = h1\n",
    "        self._h2 = h2\n",
    "        self._p = p\n",
    "        \n",
    "    @property\n",
    "    def main(self):\n",
    "        return self._main\n",
    "    \n",
    "    @property\n",
    "    def a(self):\n",
    "        return self._a\n",
    "    \n",
    "    @property\n",
    "    def h1(self):\n",
    "        return self._h1\n",
    "    \n",
    "    @property\n",
    "    def h2(self):\n",
    "        return self._h2\n",
    "    \n",
    "    @property\n",
    "    def p(self):\n",
    "        return self._p\n",
    "\n",
    "\n",
    "class Noticia:\n",
    "    \"\"\"\n",
    "    Define a estrutura da pagina inicial do site do g1.globo.com\n",
    "    \"\"\"\n",
    "    def __init__(self, url, titulo):\n",
    "        self._titulo = titulo\n",
    "        self._url = url\n",
    "        self._hashe = hash(url)\n",
    "        \n",
    "    @property\n",
    "    def titulo(self):\n",
    "        return self._titulo\n",
    "    \n",
    "    @property\n",
    "    def url(self):\n",
    "        return self._url\n",
    "    \n",
    "    @property\n",
    "    def hashe(self):\n",
    "        return self._hashe\n",
    "    \n",
    "    def __eq__(self, outro):\n",
    "        return self.hashe == outro.hashe\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"URL: {0}\\nTITULO: {1}\\n\".format(self.url, self.titulo)\n",
    "    \n",
    "\n",
    "class Artigo:\n",
    "    \"\"\"\n",
    "    Define a estrutura das paginas de artigos do site do g1.globo.com\n",
    "    \"\"\"\n",
    "    def __init__(self, url, titulo, subtitulo, data):\n",
    "        self._url = url\n",
    "        self._titulo = titulo\n",
    "        self._subtitulo = subtitulo\n",
    "        self._data = data\n",
    "        self._hashe = hash(url)\n",
    "        \n",
    "    @property\n",
    "    def url(self):\n",
    "        return self._url\n",
    "    \n",
    "    @property\n",
    "    def titulo(self):\n",
    "        return self._titulo\n",
    "    \n",
    "    @property\n",
    "    def subtitulo(self):\n",
    "        return self._subtitulo\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def hashe(self):\n",
    "        return self._hashe\n",
    "    \n",
    "    def __eq__(self, outro):\n",
    "        return self.hashe == outro.hashe\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"URL: {0}\\nTITLE: {1}\\nSUB: {2}\\nDATA: {3}\".format(self.url, self.titulo, self.subtitulo, self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def __init__(self, site):\n",
    "        self._site = site\n",
    "        self._chromeOptions = Options()\n",
    "        self._chromeOptions.add_argument('--headless')\n",
    "        self._driver = 'chromedriver'\n",
    "        self._artigos = []\n",
    "        self._noticias = []\n",
    "        \n",
    "    def getPage(self, url):\n",
    "        driver = webdriver.Chrome(executable_path=self._driver, chrome_options=self._chromeOptions)\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        return BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    def getArtigo(self, url):\n",
    "        artigo_html = requests.get(url)\n",
    "        artigo_html.raise_for_status()\n",
    "        bs_artigo = BeautifulSoup(artigo_html.text, 'html.parser')\n",
    "        try:\n",
    "            titulo = bs_artigo.find('h1', self._site.h1).get_text()\n",
    "            sub = bs_artigo.find('h2', self._site.h2).get_text()\n",
    "            data = bs_artigo.find('p', self._site.p).time['datetime']\n",
    "        except AttributeError:\n",
    "            print('Não foi possivel achar os atributos na seguite url:!!!')\n",
    "            print(url)\n",
    "            print()\n",
    "            return None\n",
    "        else:\n",
    "            artigo = Artigo(url, titulo, sub, data)\n",
    "            return artigo\n",
    "\n",
    "    def scraping(self, url):\n",
    "        bsObject = self.getPage(url)\n",
    "        for a in bsObject.find('main', self._site.main).find_all('a', self._site.a):\n",
    "            if re.search('^(https://g1.globo.com/index).*', a['href']) is None:\n",
    "                noticia = Noticia(a['href'], a.get_text())\n",
    "                if noticia not in self._noticias:\n",
    "                    self._noticias.append(noticia)\n",
    "                    artigo = self.getArtigo(noticia.url)\n",
    "                    if artigo is not None:\n",
    "                        print(artigo)\n",
    "                        print()\n",
    "                        self._artigos.append(artigo)\n",
    "            else:\n",
    "                r1 = input('deseja seguir o link[s/n]: {}'.format(a['href']))\n",
    "                if r1.lower().strip() == 's':\n",
    "                    self.scraping(a['href'])\n",
    "    \n",
    "    @property\n",
    "    def artigos(self):\n",
    "        return self._artigos\n",
    "\n",
    "    @property\n",
    "    def noticias(self):\n",
    "        return self._noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd037f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrs = {\n",
    "    'main': {'id': 'glb-main-home'},\n",
    "    'a': {'href': re.compile('^(https://g1.globo.com).*')},\n",
    "    'h1': {'class': 'content-head__title'},\n",
    "    'h2': {'class': 'content-head__subtitle'},\n",
    "    'p': {'class': 'content-publication-data__updated'}\n",
    "}\n",
    "\n",
    "site = Site(**attrs)\n",
    "crawler = Crawler(site)\n",
    "crawler.scraping('https://g1.globo.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161d44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2439614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea932f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
